{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f3efce",
   "metadata": {},
   "source": [
    "# ====== DECISION TREE IMPLEMENTATION FROM SCRATCH  ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d8af9",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b370739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install memory profiler for memory calculation\n",
    "#!pip install -U memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf05e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "# For time calculation\n",
    "import time\n",
    "# import DecisionTreeClassifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a5e86",
   "metadata": {},
   "source": [
    "# Data Purity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d708ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493b1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is dataframe Target column\n",
    "def data_purity_check(target_col):\n",
    "    # When only one class is available for classification\n",
    "    if len(set(target_col)) == 1:\n",
    "        return True\n",
    "    # When several classes are there for classification\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a82fda",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cecf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is dataframe itself\n",
    "def classification(cf):\n",
    "    target_col = cf.label.values\n",
    "    list_of_count_of_target = list(Counter(target_col).items())\n",
    "    sorted_list_of_count_of_target = sorted(list_of_count_of_target, key=lambda x: x[1])\n",
    "    result_class = sorted_list_of_count_of_target[-1][0]\n",
    "    return(result_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d054a",
   "metadata": {},
   "source": [
    "# Potential Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2037a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is dataframe itself\n",
    "def find_potential_splits(fps_df):\n",
    "    partition_box = dict()\n",
    "    for col in fps_df.columns[:-1]: # Not including label column\n",
    "        # Finding the partition corresponding to each feature\n",
    "        unique_sorted_values_each_col = sorted(list(set(fps_df[col].values)))\n",
    "        \n",
    "        # Check for Continuous Variable\n",
    "        if (fps_df[col].dtype.name in ['int', 'float', 'int64', 'float64']):\n",
    "            # Finding the mid point between each sorted unique values in per column\n",
    "            temp = [(unique_sorted_values_each_col[i] + unique_sorted_values_each_col[i-1])/2 for i in range(1, len(unique_sorted_values_each_col))]\n",
    "        \n",
    "        # Check for Categorical Variable\n",
    "        elif (fps_df[col].dtype.name in ['object', 'category', 'bool', 'boolean']): \n",
    "            temp = unique_sorted_values_each_col\n",
    "        \n",
    "        # storing  the mid values list corresponding to each key (here column name)\n",
    "        partition_box[col] = temp\n",
    "    return partition_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d2239",
   "metadata": {},
   "source": [
    "# Splitting the data\n",
    "Column is selected first and then the value at which split is to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ab25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is dataframe itself, splitting column, splitting point\n",
    "# It will return all the points on either side of the split line\n",
    "def splitting(s_df, col_of_split, point_of_split):\n",
    "    \n",
    "    # For Continuous Variable\n",
    "    if s_df[col_of_split].dtype.name in ['int', 'float', 'int64', 'float64']:\n",
    "        left_part_of_split = s_df[s_df[col_of_split] <= point_of_split]\n",
    "        right_part_of_split = s_df[s_df[col_of_split] > point_of_split]\n",
    "    # For Categorical Variable\n",
    "    elif s_df[col_of_split].dtype.name in ['object', 'category', 'bool', 'boolean']:\n",
    "        left_part_of_split = s_df[s_df[col_of_split] == point_of_split]\n",
    "        right_part_of_split = s_df[s_df[col_of_split] != point_of_split]\n",
    "    \n",
    "    return left_part_of_split, right_part_of_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb49fa8",
   "metadata": {},
   "source": [
    "# Calculation of entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261a112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(ce_df):\n",
    "    target = ce_df.label.values\n",
    "    target_values_count = np.array(list(Counter(target).values()))\n",
    "    probabilities_of_each_class = target_values_count/float(sum(target_values_count))\n",
    "    entropy = sum(probabilities_of_each_class *(-np.log2(probabilities_of_each_class)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bbf348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(left_data, right_data):\n",
    "    # Probability of occurance of left data points\n",
    "    probability_left_data = left_data.shape[0]/ float(left_data.shape[0] + right_data.shape[0])\n",
    "    # Probability of occurance of right data points\n",
    "    probability_right_data = 1 - probability_left_data\n",
    "    overall_entropy = (probability_left_data*calculate_entropy(left_data)) + (probability_right_data*calculate_entropy(right_data))\n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b0c8e",
   "metadata": {},
   "source": [
    "# Calculation of gini-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7809de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_individual_side_gini(cg_df):\n",
    "    target = cg_df.label.values\n",
    "    target_values_count = np.array(list(Counter(target).values()))\n",
    "    probabilities_of_each_class = target_values_count/float(sum(target_values_count))\n",
    "    impurity = 1 - sum(probabilities_of_each_class ** 2)\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb9b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_gini(left_data, right_data):\n",
    "    # Probability of occurance of left data points\n",
    "    probability_left_data = left_data.shape[0]/ float(left_data.shape[0] + right_data.shape[0])\n",
    "    # Probability of occurance of right data points\n",
    "    probability_right_data = 1 - probability_left_data\n",
    "    # Calculating overall gini combining weigted impurities from both the left and right parts\n",
    "    overall_impurity = (probability_left_data*calculate_individual_side_gini(left_data)) + (probability_right_data*calculate_individual_side_gini(right_data))\n",
    "    return overall_impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdaf1a",
   "metadata": {},
   "source": [
    "# Finding the best possible split by Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "250ba3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_by_information_gain(ig_df, potential_split_dictionary):\n",
    "    \"\"\"Finding the feature or column and split_point with the highest information gain.\"\"\"\n",
    "    \n",
    "    # Initial entropy to compare the improvement\n",
    "    initial_entropy = calculate_entropy(ig_df)\n",
    "    best_information_gain = -np.inf\n",
    "    \n",
    "    for split_col in potential_split_dictionary.keys():\n",
    "        for split_value in potential_split_dictionary[split_col]:\n",
    "            left_data, right_data = splitting(ig_df, split_col, split_value)\n",
    "            current_overall_entropy = calculate_overall_entropy(left_data, right_data)\n",
    "            current_information_gain = initial_entropy - current_overall_entropy\n",
    "            \n",
    "            if current_information_gain > best_information_gain:\n",
    "                best_information_gain = current_information_gain\n",
    "                best_col_of_split = split_col\n",
    "                best_point_of_split = split_value\n",
    "                \n",
    "    return best_col_of_split, best_point_of_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e0a86",
   "metadata": {},
   "source": [
    "# Finding the best possible split by Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f745344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_by_gini(g_df, potential_split_dictionary):\n",
    "    \"\"\"Finding the feature or column and split_point with the minimum gini.\"\"\"\n",
    "    best_overall_gini = 7777\n",
    "    for split_col in potential_split_dictionary.keys():\n",
    "        for split_value in potential_split_dictionary[split_col]:\n",
    "            left_data, right_data = splitting(g_df, split_col, split_value)\n",
    "            current_overall_gini = calculate_overall_gini(left_data, right_data)\n",
    "            \n",
    "            if current_overall_gini < best_overall_gini:\n",
    "                best_overall_gini = current_overall_gini\n",
    "                best_col_of_split = split_col\n",
    "                best_point_of_split = split_value\n",
    "                \n",
    "    return best_col_of_split, best_point_of_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf0dcf",
   "metadata": {},
   "source": [
    "# Creating main decision tree function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87962854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeClassifier(dt_df, current_depth = 0, max_depth=np.inf, split_type='entropy'):\n",
    "    \n",
    "    \n",
    "    # Base case: When we get pure sample -> return the class\n",
    "    if data_purity_check(dt_df.label) or current_depth == max_depth:\n",
    "        return classification(dt_df)\n",
    "    \n",
    "    else:\n",
    "        current_depth +=1\n",
    "        potential_splits = find_potential_splits(dt_df)\n",
    "        \n",
    "        if len(potential_splits) == 0:\n",
    "            return classification(dt_df)\n",
    "            \n",
    "        \n",
    "        # Split point and column based on entropy and gini split_type\n",
    "        if split_type == 'entropy':\n",
    "            best_col_of_split, best_point_of_split = best_split_by_information_gain(dt_df, potential_splits)\n",
    "        elif split_type == 'gini':\n",
    "            best_col_of_split, best_point_of_split = best_split_by_gini(dt_df, potential_splits)\n",
    "            \n",
    "            \n",
    "        left_part_of_split, right_part_of_split = splitting(dt_df, best_col_of_split, best_point_of_split)\n",
    "        \n",
    "        if dt_df[best_col_of_split].dtype.name in ['int', 'float', 'int64', 'float64']:   \n",
    "            split_question = \"{} <= {}\".format(best_col_of_split, best_point_of_split)\n",
    "            \n",
    "        elif dt_df[best_col_of_split].dtype.name in ['object', 'category', 'bool', 'boolean']: \n",
    "            print(\"the best col of split is {} and best point is {}\".format(best_col_of_split, best_point_of_split))\n",
    "            split_question = \"{} = {}\".format(best_col_of_split, best_point_of_split)\n",
    "            \n",
    "            \n",
    "        flow_dict = {split_question:[]}\n",
    "        \n",
    "        \n",
    "        if_yes = decisionTreeClassifier(left_part_of_split, current_depth, max_depth) \n",
    "        if_no = decisionTreeClassifier(right_part_of_split, current_depth, max_depth)\n",
    "        \n",
    "        if if_yes == if_no:\n",
    "            flow_dict = if_yes\n",
    "        else:       \n",
    "            flow_dict[split_question].append(if_yes)\n",
    "            flow_dict[split_question].append(if_no)\n",
    "        \n",
    "    return flow_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95260812",
   "metadata": {},
   "source": [
    "# Classifying per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f69b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_data_classify(test_row, reference_tree):\n",
    "    # We first need to check our test row with the questions as per our reference tree\n",
    "    main_question = list(reference_tree.keys())[0]\n",
    "    question = main_question.split()\n",
    "    # question[0] = feature_name\n",
    "    # question[1] = <=\n",
    "    # question[2] = split_point\n",
    "    \n",
    "    if question[1] == '<=':\n",
    "        if test_row[question[0]] <= float(question[2]):\n",
    "            answer = reference_tree[main_question][0]\n",
    "        else:\n",
    "            answer = reference_tree[main_question][1]\n",
    "    else:\n",
    "        if str(test_row[question[0]]) == question[2]:\n",
    "            answer = reference_tree[main_question][0]\n",
    "        else:\n",
    "            answer = reference_tree[main_question][1]\n",
    "        \n",
    "    # Checking if answer is an instance of dictionary or not\n",
    "    # If answer is one of the class then that is our final result otherwise if it's a dictionary we'll do recursion\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        return per_data_classify(test_row, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80e300",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3691e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_test, main_tree):\n",
    "    prediction = []\n",
    "    total_test_rows = df_test.shape[0]\n",
    "    for ind in df_test.index:\n",
    "        test_row = df_test.loc[ind]\n",
    "        prediction.append(per_data_classify(test_row, main_tree)) \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5a536",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7717b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_tt, train_size, seed_value=23):\n",
    "    population_set = df_tt.index.tolist()\n",
    "    length_of_dataset = df_tt.shape[0]\n",
    "    # Setting the seed so that everytime the function is run we get same values for corresponding to a particular seed value\n",
    "    random.seed(seed_value)\n",
    "    # Considering train size to be given between 0 to 1\n",
    "    train_index = random.sample(population_set, int(train_size*length_of_dataset))\n",
    "    test_index = set(population_set) - set(train_index)\n",
    "    df_tt_train = df_tt.loc[train_index] \n",
    "    df_tt_test = df_tt.loc[test_index]\n",
    "    result = df_tt_train, df_tt_test\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ff240",
   "metadata": {},
   "source": [
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954b719",
   "metadata": {},
   "source": [
    "# Testing the above code using a `Abalon` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967277ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_Weight</th>\n",
       "      <th>Shucked_Weight</th>\n",
       "      <th>Viscera_Weight</th>\n",
       "      <th>Shell_Weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_Weight  Shucked_Weight  Viscera_Weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_Weight  Rings label  \n",
       "0         0.150     15     M  \n",
       "1         0.070      7     M  \n",
       "2         0.210      9     F  \n",
       "3         0.155     10     M  \n",
       "4         0.055      7     I  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names for DataSet\n",
    "col_names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_Weight\",\n",
    "\"Shucked_Weight\", \"Viscera_Weight\", \"Shell_Weight\", \"Rings\"]\n",
    "# Reading the data \"Abalone\"\n",
    "df = pd.read_csv('abalone.data', names = col_names)\n",
    "# Dropping the \"Sex\" column and storing it into \"label\" column at the end\n",
    "target = df.Sex\n",
    "df.drop(['Sex'], axis =1, inplace=True)\n",
    "df['label'] = target\n",
    "# Seeing top 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd3481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Length          4177 non-null   float64\n",
      " 1   Diameter        4177 non-null   float64\n",
      " 2   Height          4177 non-null   float64\n",
      " 3   Whole_Weight    4177 non-null   float64\n",
      " 4   Shucked_Weight  4177 non-null   float64\n",
      " 5   Viscera_Weight  4177 non-null   float64\n",
      " 6   Shell_Weight    4177 non-null   float64\n",
      " 7   Rings           4177 non-null   int64  \n",
      " 8   label           4177 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of all the features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ef8650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole_Weight      0\n",
       "Shucked_Weight    0\n",
       "Viscera_Weight    0\n",
       "Shell_Weight      0\n",
       "Rings             0\n",
       "label             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Null Values in all the features\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b732045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaibh\\anaconda3\\envs\\env1\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Length', ylabel='Diameter'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(df.Length, df.Diameter, hue = df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b26795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Length          4177 non-null   float64\n",
      " 1   Diameter        4177 non-null   float64\n",
      " 2   Height          4177 non-null   float64\n",
      " 3   Whole_Weight    4177 non-null   float64\n",
      " 4   Shucked_Weight  4177 non-null   float64\n",
      " 5   Viscera_Weight  4177 non-null   float64\n",
      " 6   Shell_Weight    4177 non-null   float64\n",
      " 7   Rings           4177 non-null   int64  \n",
      " 8   label           4177 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 293.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8645f",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d1b99",
   "metadata": {},
   "source": [
    "## Comparison of my code and sklearn code based on time, accuracy, precision, recall with varying max_depth (split-criterian: Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71693aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using entropy as \"criteria for creating leaf nodes\"\n",
    "# Changing the Max-depth and calculating the accuracy and f1-score\n",
    "max_depth = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] # Changing from 2 to 20 \n",
    "depth_time, depth_time_sk = [], []\n",
    "depth_accuracy, depth_accuracy_sk = [], []\n",
    "depth_f1_score, depth_f1_score_sk = [], []\n",
    "depth_precision, depth_precision_sk = [], []\n",
    "depth_recall, depth_recall_sk = [], []\n",
    "\n",
    "# Looping through all the values of depths\n",
    "for depth in max_depth:\n",
    "    # Dividing into train and test based on split size\n",
    "    df_train, df_test = train_test_split(df, .8)\n",
    "    \n",
    "    # Calculation and training of model and training time \n",
    "    start = time.time()\n",
    "    # Model Training\n",
    "    main_tree = decisionTreeClassifier(df_train, max_depth=depth, split_type='entropy')\n",
    "    end = time.time()\n",
    "    # Storing training time taken into depth_time list\n",
    "    depth_time.append(end-start)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------    \n",
    "    \n",
    "    # Calculation and training of model and training time of sklearn model\n",
    "    start = time.time()\n",
    "    # Model Training\n",
    "    sk_model = DecisionTreeClassifier(criterion='entropy', max_depth=depth)\n",
    "    # fit the model\n",
    "    sk_model.fit(df_train.iloc[:, :-1], df_train.iloc[:, -1])\n",
    "    end = time.time()\n",
    "    # Storing training time taken into depth_time list\n",
    "    depth_time_sk.append(end-start)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Making prediction\n",
    "    y_pred = predict(df_test, main_tree)\n",
    "    y_pred_sk = sk_model.predict(df_test.iloc[:, :-1])\n",
    "    \n",
    "    # Finding Testing Accuracy\n",
    "    y_accuracy = accuracy_score(df_test.iloc[:, -1], y_pred)\n",
    "    depth_accuracy.append(y_accuracy)\n",
    "    #-----------------------------------------------------\n",
    "    y_accuracy_sk = accuracy_score(df_test.iloc[:, -1], y_pred_sk)\n",
    "    depth_accuracy_sk.append(y_accuracy_sk)\n",
    "    \n",
    "    # Finding F1-Score\n",
    "    y_f1_score = f1_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_f1_score.append(y_f1_score)\n",
    "    #------------------------------------------------------\n",
    "    y_f1_score_sk = f1_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_f1_score_sk.append(y_f1_score_sk)\n",
    "    \n",
    "    # Finding Precision\n",
    "    y_precision = precision_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_precision.append(y_precision)\n",
    "    #------------------------------------------------------\n",
    "    y_precision_sk = precision_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_precision_sk.append(y_precision_sk)\n",
    "    \n",
    "    # Finding Recall\n",
    "    y_recall = recall_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_recall.append(y_recall)\n",
    "    #--------------------------------------------------------\n",
    "    y_recall_sk = recall_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_recall_sk.append(y_recall_sk)\n",
    "    \n",
    "\n",
    "# Creating dataframe of all the results achieved\n",
    "varying_max_depth_entropy_dict = {'Depth':max_depth, \n",
    "                                 'Training_Time_My':depth_time,\n",
    "                                 'Training_Time_Sk':depth_time_sk,\n",
    "                                 'Testing_Accuracy_My':depth_accuracy,\n",
    "                                 'Testing_Accuracy_Sk':depth_accuracy_sk,\n",
    "                                 'Testing_F1_My':depth_f1_score,\n",
    "                                 'Testing_F1_Sk':depth_f1_score_sk,\n",
    "                                 'Testing_Precision_My':depth_precision,\n",
    "                                 'Testing_Precision_Sk':depth_precision_sk,\n",
    "                                 'Testing_Recall_My':depth_recall,\n",
    "                                 'Testing_Recall_Sk':depth_recall_sk}\n",
    "\n",
    "\n",
    "varying_max_depth_entropy_df = pd.DataFrame(varying_max_depth_entropy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4638013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Training_Time_My</th>\n",
       "      <th>Training_Time_Sk</th>\n",
       "      <th>Testing_Accuracy_My</th>\n",
       "      <th>Testing_Accuracy_Sk</th>\n",
       "      <th>Testing_F1_My</th>\n",
       "      <th>Testing_F1_Sk</th>\n",
       "      <th>Testing_Precision_My</th>\n",
       "      <th>Testing_Precision_Sk</th>\n",
       "      <th>Testing_Recall_My</th>\n",
       "      <th>Testing_Recall_Sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11.397162</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.523923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15.539232</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "      <td>0.550239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>20.607886</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>27.346186</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.547847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>33.541787</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "      <td>0.527512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>41.078960</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.551435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>48.428648</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.541866</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.541866</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.541866</td>\n",
       "      <td>0.547847</td>\n",
       "      <td>0.541866</td>\n",
       "      <td>0.547847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>57.523864</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>58.484606</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.520335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>64.705553</td>\n",
       "      <td>0.031657</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>69.851390</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.523923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>76.111301</td>\n",
       "      <td>0.016140</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.519139</td>\n",
       "      <td>0.528708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>79.305228</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.520335</td>\n",
       "      <td>0.516746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>85.667130</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.514354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>86.082004</td>\n",
       "      <td>0.027643</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.507177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>88.460686</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.508373</td>\n",
       "      <td>0.510766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>92.083315</td>\n",
       "      <td>0.035422</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>89.631356</td>\n",
       "      <td>0.028008</td>\n",
       "      <td>0.503589</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.503589</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.503589</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.503589</td>\n",
       "      <td>0.517943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>89.544009</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.510766</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.510766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth  Training_Time_My  Training_Time_Sk  Testing_Accuracy_My  \\\n",
       "0       2         11.397162          0.015304             0.523923   \n",
       "1       3         15.539232          0.013004             0.550239   \n",
       "2       4         20.607886          0.015626             0.561005   \n",
       "3       5         27.346186          0.016005             0.551435   \n",
       "4       6         33.541787          0.015628             0.527512   \n",
       "5       7         41.078960          0.016948             0.555024   \n",
       "6       8         48.428648          0.019824             0.541866   \n",
       "7       9         57.523864          0.031257             0.522727   \n",
       "8      10         58.484606          0.034280             0.514354   \n",
       "9      11         64.705553          0.031657             0.528708   \n",
       "10     12         69.851390          0.031252             0.517943   \n",
       "11     13         76.111301          0.016140             0.519139   \n",
       "12     14         79.305228          0.046883             0.520335   \n",
       "13     15         85.667130          0.031252             0.508373   \n",
       "14     16         86.082004          0.027643             0.513158   \n",
       "15     17         88.460686          0.032008             0.508373   \n",
       "16     18         92.083315          0.035422             0.500000   \n",
       "17     19         89.631356          0.028008             0.503589   \n",
       "18     20         89.544009          0.040008             0.501196   \n",
       "\n",
       "    Testing_Accuracy_Sk  Testing_F1_My  Testing_F1_Sk  Testing_Precision_My  \\\n",
       "0              0.523923       0.523923       0.523923              0.523923   \n",
       "1              0.550239       0.550239       0.550239              0.550239   \n",
       "2              0.561005       0.561005       0.561005              0.561005   \n",
       "3              0.547847       0.551435       0.547847              0.551435   \n",
       "4              0.527512       0.527512       0.527512              0.527512   \n",
       "5              0.551435       0.555024       0.551435              0.555024   \n",
       "6              0.547847       0.541866       0.547847              0.541866   \n",
       "7              0.521531       0.522727       0.521531              0.522727   \n",
       "8              0.520335       0.514354       0.520335              0.514354   \n",
       "9              0.522727       0.528708       0.522727              0.528708   \n",
       "10             0.523923       0.517943       0.523923              0.517943   \n",
       "11             0.528708       0.519139       0.528708              0.519139   \n",
       "12             0.516746       0.520335       0.516746              0.520335   \n",
       "13             0.514354       0.508373       0.514354              0.508373   \n",
       "14             0.507177       0.513158       0.507177              0.513158   \n",
       "15             0.510766       0.508373       0.510766              0.508373   \n",
       "16             0.502392       0.500000       0.502392              0.500000   \n",
       "17             0.517943       0.503589       0.517943              0.503589   \n",
       "18             0.510766       0.501196       0.510766              0.501196   \n",
       "\n",
       "    Testing_Precision_Sk  Testing_Recall_My  Testing_Recall_Sk  \n",
       "0               0.523923           0.523923           0.523923  \n",
       "1               0.550239           0.550239           0.550239  \n",
       "2               0.561005           0.561005           0.561005  \n",
       "3               0.547847           0.551435           0.547847  \n",
       "4               0.527512           0.527512           0.527512  \n",
       "5               0.551435           0.555024           0.551435  \n",
       "6               0.547847           0.541866           0.547847  \n",
       "7               0.521531           0.522727           0.521531  \n",
       "8               0.520335           0.514354           0.520335  \n",
       "9               0.522727           0.528708           0.522727  \n",
       "10              0.523923           0.517943           0.523923  \n",
       "11              0.528708           0.519139           0.528708  \n",
       "12              0.516746           0.520335           0.516746  \n",
       "13              0.514354           0.508373           0.514354  \n",
       "14              0.507177           0.513158           0.507177  \n",
       "15              0.510766           0.508373           0.510766  \n",
       "16              0.502392           0.500000           0.502392  \n",
       "17              0.517943           0.503589           0.517943  \n",
       "18              0.510766           0.501196           0.510766  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_max_depth_entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cddeefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_max_depth_entropy_df.to_csv('varying_max_depth_entropy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588d00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2127999a",
   "metadata": {},
   "source": [
    "## Comparison of my code and sklearn code based on time, accuracy, precision, recall with varying max_depth (split-criterian: gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dab041f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gini as \"criteria for creating leaf nodes\"\n",
    "# Changing the Max-depth and calculating the accuracy and f1-score\n",
    "max_depth = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20] # Changing from 2 to 20 \n",
    "depth_time, depth_time_sk = [], []\n",
    "depth_accuracy, depth_accuracy_sk = [], []\n",
    "depth_f1_score, depth_f1_score_sk = [], []\n",
    "depth_precision, depth_precision_sk = [], []\n",
    "depth_recall, depth_recall_sk = [], []\n",
    "\n",
    "# Looping through all the values of depths\n",
    "for depth in max_depth:\n",
    "    # Dividing into train and test based on split size\n",
    "    df_train, df_test = train_test_split(df, .8)\n",
    "    \n",
    "    # Calculation and training of model and training time \n",
    "    start = time.time()\n",
    "    # Model Training\n",
    "    main_tree = decisionTreeClassifier(df_train, max_depth=depth, split_type='gini')\n",
    "    end = time.time()\n",
    "    # Storing training time taken into depth_time list\n",
    "    depth_time.append(end-start)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------    \n",
    "    \n",
    "    # Calculation and training of model and training time of sklearn model\n",
    "    start = time.time()\n",
    "    # Model Training\n",
    "    sk_model = DecisionTreeClassifier(criterion='gini', max_depth=depth)\n",
    "    # fit the model\n",
    "    sk_model.fit(df_train.iloc[:, :-1], df_train.iloc[:, -1])\n",
    "    end = time.time()\n",
    "    # Storing training time taken into depth_time list\n",
    "    depth_time_sk.append(end-start)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Making prediction\n",
    "    y_pred = predict(df_test, main_tree)\n",
    "    y_pred_sk = sk_model.predict(df_test.iloc[:, :-1])\n",
    "    \n",
    "    # Finding Accuracy\n",
    "    y_accuracy = accuracy_score(df_test.iloc[:, -1], y_pred)\n",
    "    depth_accuracy.append(y_accuracy)\n",
    "    #-----------------------------------------------------\n",
    "    y_accuracy_sk = accuracy_score(df_test.iloc[:, -1], y_pred_sk)\n",
    "    depth_accuracy_sk.append(y_accuracy_sk)\n",
    "    \n",
    "    # Finding F1-Score\n",
    "    y_f1_score = f1_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_f1_score.append(y_f1_score)\n",
    "    #------------------------------------------------------\n",
    "    y_f1_score_sk = f1_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_f1_score_sk.append(y_f1_score_sk)\n",
    "    \n",
    "    # Finding Precision\n",
    "    y_precision = precision_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_precision.append(y_precision)\n",
    "    #------------------------------------------------------\n",
    "    y_precision_sk = precision_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_precision_sk.append(y_precision_sk)\n",
    "    \n",
    "    # Finding Recall\n",
    "    y_recall = recall_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "    depth_recall.append(y_recall)\n",
    "    #--------------------------------------------------------\n",
    "    y_recall_sk = recall_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "    depth_recall_sk.append(y_recall_sk)\n",
    "    \n",
    "\n",
    "# Creating dataframe of all the results achieved\n",
    "varying_max_depth_gini_dict = {'Depth':max_depth, \n",
    "                                 'Training_Time_My':depth_time,\n",
    "                                 'Training_Time_Sk':depth_time_sk,\n",
    "                                 'Testing_Accuracy_My':depth_accuracy,\n",
    "                                 'Testing_Accuracy_Sk':depth_accuracy_sk,\n",
    "                                 'Testing_F1_My':depth_f1_score,\n",
    "                                 'Testing_F1_Sk':depth_f1_score_sk,\n",
    "                                 'Testing_Precision_My':depth_precision,\n",
    "                                 'Testing_Precision_Sk':depth_precision_sk,\n",
    "                                 'Testing_Recall_My':depth_recall,\n",
    "                                 'Testing_Recall_Sk':depth_recall_sk}\n",
    "\n",
    "\n",
    "varying_max_depth_gini_df = pd.DataFrame(varying_max_depth_gini_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bbe2a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Training_Time_My</th>\n",
       "      <th>Training_Time_Sk</th>\n",
       "      <th>Testing_Accuracy_My</th>\n",
       "      <th>Testing_Accuracy_Sk</th>\n",
       "      <th>Testing_F1_My</th>\n",
       "      <th>Testing_F1_Sk</th>\n",
       "      <th>Testing_Precision_My</th>\n",
       "      <th>Testing_Precision_Sk</th>\n",
       "      <th>Testing_Recall_My</th>\n",
       "      <th>Testing_Recall_Sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10.067374</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>0.525120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15.503729</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.528708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>21.337162</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>27.965792</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.549043</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.549043</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.549043</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.549043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>34.475090</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.553828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>41.018971</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>47.243325</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.538278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>54.338260</td>\n",
       "      <td>0.031247</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.537081</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.537081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>60.534106</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.509569</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.509569</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.509569</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.509569</td>\n",
       "      <td>0.540670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>66.995388</td>\n",
       "      <td>0.020012</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>0.532297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>71.518081</td>\n",
       "      <td>0.029658</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.534689</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.534689</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.534689</td>\n",
       "      <td>0.502392</td>\n",
       "      <td>0.534689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>75.723140</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.496411</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.496411</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.496411</td>\n",
       "      <td>0.532297</td>\n",
       "      <td>0.496411</td>\n",
       "      <td>0.532297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>79.746167</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.538278</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.538278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>85.546738</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.474880</td>\n",
       "      <td>0.539474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>87.904500</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.482057</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.482057</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.482057</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.482057</td>\n",
       "      <td>0.507177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>88.731808</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.471292</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.471292</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.471292</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.471292</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>88.812648</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>92.068643</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.465311</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.465311</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.465311</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.465311</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>92.980630</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.515550</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.515550</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.515550</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.515550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth  Training_Time_My  Training_Time_Sk  Testing_Accuracy_My  \\\n",
       "0       2         10.067374          0.008002             0.525120   \n",
       "1       3         15.503729          0.008003             0.538278   \n",
       "2       4         21.337162          0.008002             0.556220   \n",
       "3       5         27.965792          0.012003             0.553828   \n",
       "4       6         34.475090          0.012003             0.539474   \n",
       "5       7         41.018971          0.016005             0.574163   \n",
       "6       8         47.243325          0.012002             0.562201   \n",
       "7       9         54.338260          0.031247             0.546651   \n",
       "8      10         60.534106          0.020005             0.509569   \n",
       "9      11         66.995388          0.020012             0.523923   \n",
       "10     12         71.518081          0.029658             0.502392   \n",
       "11     13         75.723140          0.020004             0.496411   \n",
       "12     14         79.746167          0.019746             0.483254   \n",
       "13     15         85.546738          0.015635             0.474880   \n",
       "14     16         87.904500          0.023745             0.482057   \n",
       "15     17         88.731808          0.020005             0.471292   \n",
       "16     18         88.812648          0.020005             0.466507   \n",
       "17     19         92.068643          0.020015             0.465311   \n",
       "18     20         92.980630          0.024006             0.466507   \n",
       "\n",
       "    Testing_Accuracy_Sk  Testing_F1_My  Testing_F1_Sk  Testing_Precision_My  \\\n",
       "0              0.525120       0.525120       0.525120              0.525120   \n",
       "1              0.528708       0.538278       0.528708              0.538278   \n",
       "2              0.558612       0.556220       0.558612              0.556220   \n",
       "3              0.549043       0.553828       0.549043              0.553828   \n",
       "4              0.553828       0.539474       0.553828              0.539474   \n",
       "5              0.551435       0.574163       0.551435              0.574163   \n",
       "6              0.538278       0.562201       0.538278              0.562201   \n",
       "7              0.537081       0.546651       0.537081              0.546651   \n",
       "8              0.540670       0.509569       0.540670              0.509569   \n",
       "9              0.532297       0.523923       0.532297              0.523923   \n",
       "10             0.534689       0.502392       0.534689              0.502392   \n",
       "11             0.532297       0.496411       0.532297              0.496411   \n",
       "12             0.538278       0.483254       0.538278              0.483254   \n",
       "13             0.539474       0.474880       0.539474              0.474880   \n",
       "14             0.507177       0.482057       0.507177              0.482057   \n",
       "15             0.513158       0.471292       0.513158              0.471292   \n",
       "16             0.521531       0.466507       0.521531              0.466507   \n",
       "17             0.526316       0.465311       0.526316              0.465311   \n",
       "18             0.515550       0.466507       0.515550              0.466507   \n",
       "\n",
       "    Testing_Precision_Sk  Testing_Recall_My  Testing_Recall_Sk  \n",
       "0               0.525120           0.525120           0.525120  \n",
       "1               0.528708           0.538278           0.528708  \n",
       "2               0.558612           0.556220           0.558612  \n",
       "3               0.549043           0.553828           0.549043  \n",
       "4               0.553828           0.539474           0.553828  \n",
       "5               0.551435           0.574163           0.551435  \n",
       "6               0.538278           0.562201           0.538278  \n",
       "7               0.537081           0.546651           0.537081  \n",
       "8               0.540670           0.509569           0.540670  \n",
       "9               0.532297           0.523923           0.532297  \n",
       "10              0.534689           0.502392           0.534689  \n",
       "11              0.532297           0.496411           0.532297  \n",
       "12              0.538278           0.483254           0.538278  \n",
       "13              0.539474           0.474880           0.539474  \n",
       "14              0.507177           0.482057           0.507177  \n",
       "15              0.513158           0.471292           0.513158  \n",
       "16              0.521531           0.466507           0.521531  \n",
       "17              0.526316           0.465311           0.526316  \n",
       "18              0.515550           0.466507           0.515550  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_max_depth_gini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84436bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_max_depth_gini_df.to_csv('varying_max_depth_gini_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933abf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14733e4b",
   "metadata": {},
   "source": [
    "## Comparing Accuracy and Time of my algo and Sklearn with varying training size (criterian-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f618dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data into different train and test using different split value\n",
    "# Considering split from 50% to 90% train split\n",
    "train_size = [.5, .6, .7, .8, .9]\n",
    "depth = [4, 7]\n",
    "\n",
    "var_train_training_acc, var_train_training_acc_sk = [], []\n",
    "var_train_time, var_train_time_sk = [], []\n",
    "var_train_acc, var_train_acc_sk = [], []\n",
    "var_train_f1_score, var_train_f1_score_sk = [], []\n",
    "var_train_precision, var_train_precision_sk = [], []\n",
    "var_train_recall, var_train_recall_sk = [], []\n",
    "var_tree_depth, var_train_size = [], []\n",
    "  \n",
    "for d in depth:\n",
    "    for i in train_size:\n",
    "        var_tree_depth.append(d)\n",
    "        var_train_size.append(i*100)\n",
    "        \n",
    "        # Dividing into train and test based on split size\n",
    "        df_train, df_test = train_test_split(df, i)\n",
    "\n",
    "        # Calculation and training of model and training time of My Algo\n",
    "        start = time.time()\n",
    "        main_tree = decisionTreeClassifier(df_train, max_depth=d, split_type='entropy')\n",
    "        end = time.time()\n",
    "        var_train_time.append(end-start)\n",
    "        #---------------------------------------------------------------------------------------\n",
    "        #---------------------------------------------------------------------------------------      \n",
    "        # Calculation and training of model and training time of sklearn model\n",
    "        start = time.time()\n",
    "        # Model Training\n",
    "        sk_model = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "        # fit the model\n",
    "        sk_model.fit(df_train.iloc[:, :-1], df_train.iloc[:, -1])\n",
    "        end = time.time()\n",
    "        # Storing training time taken into depth_time list\n",
    "        var_train_time_sk.append(end-start)\n",
    "        \n",
    "        \n",
    "        # Making prediction on training data\n",
    "        y_pred_train = predict(df_train.iloc[:, :-1], main_tree)\n",
    "        y_pred_train_sk = sk_model.predict(df_train.iloc[:, :-1])\n",
    "\n",
    "        # Finding Training Accuracy\n",
    "        y_accuracy_train = accuracy_score(df_train.iloc[:, -1], y_pred_train)\n",
    "        var_train_training_acc.append(y_accuracy_train)\n",
    "        #-----------------------------------------------------\n",
    "        y_accuracy_train_sk = accuracy_score(df_train.iloc[:, -1], y_pred_train_sk)\n",
    "        var_train_training_acc_sk.append(y_accuracy_train_sk)\n",
    "        \n",
    "        \n",
    "        # Making prediction on testing data\n",
    "        y_pred = predict(df_test, main_tree)\n",
    "        y_pred_sk = sk_model.predict(df_test.iloc[:, :-1])\n",
    "\n",
    "        # Finding Accuracy\n",
    "        y_accuracy = accuracy_score(df_test.iloc[:, -1], y_pred)\n",
    "        var_train_acc.append(y_accuracy)\n",
    "        #-----------------------------------------------------\n",
    "        y_accuracy_sk = accuracy_score(df_test.iloc[:, -1], y_pred_sk)\n",
    "        var_train_acc_sk.append(y_accuracy_sk)\n",
    "\n",
    "        # Finding F1-Score\n",
    "        y_f1_score = f1_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_f1_score.append(y_f1_score)\n",
    "        #------------------------------------------------------\n",
    "        y_f1_score_sk = f1_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_f1_score_sk.append(y_f1_score_sk)\n",
    "\n",
    "        # Finding Precision\n",
    "        y_precision = precision_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_precision.append(y_precision)\n",
    "        #------------------------------------------------------\n",
    "        y_precision_sk = precision_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_precision_sk.append(y_precision_sk)\n",
    "\n",
    "        # Finding Recall\n",
    "        y_recall = recall_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_recall.append(y_recall)\n",
    "        #--------------------------------------------------------\n",
    "        y_recall_sk = recall_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_recall_sk.append(y_recall_sk)\n",
    "        \n",
    "# Creating dataframe of all the results achieved\n",
    "varying_train_size_entropy_dict = {'Depth': var_tree_depth,\n",
    "                                 'training_size':var_train_size, \n",
    "                                 'Training_Time_My':var_train_time,\n",
    "                                 'Training_Time_Sk':var_train_time_sk,\n",
    "                                 'Training_Accuracy_My':var_train_training_acc,\n",
    "                                 'Training_Accuracy_Sk':var_train_training_acc_sk,\n",
    "                                 'Testing_Accuracy_My':var_train_acc,\n",
    "                                 'Testing_Accuracy_Sk':var_train_acc_sk,\n",
    "                                 'Testing_F1_My':var_train_f1_score, \n",
    "                                 'Testing_F1_Sk':var_train_f1_score_sk,\n",
    "                                 'Testing_Precision_My':var_train_precision, \n",
    "                                 'Testing_Precision_Sk':var_train_precision_sk,\n",
    "                                 'Testing_Recall_My':var_train_recall, \n",
    "                                 'Testing_Recall_Sk':var_train_recall_sk }\n",
    "\n",
    "\n",
    "varying_train_size_entropy_df = pd.DataFrame(varying_train_size_entropy_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37083d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>training_size</th>\n",
       "      <th>Training_Time_My</th>\n",
       "      <th>Training_Time_Sk</th>\n",
       "      <th>Training_Accuracy_My</th>\n",
       "      <th>Training_Accuracy_Sk</th>\n",
       "      <th>Testing_Accuracy_My</th>\n",
       "      <th>Testing_Accuracy_Sk</th>\n",
       "      <th>Testing_F1_My</th>\n",
       "      <th>Testing_F1_Sk</th>\n",
       "      <th>Testing_Precision_My</th>\n",
       "      <th>Testing_Precision_Sk</th>\n",
       "      <th>Testing_Recall_My</th>\n",
       "      <th>Testing_Recall_Sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.934498</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.546194</td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.546194</td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.546194</td>\n",
       "      <td>0.546673</td>\n",
       "      <td>0.546194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.813262</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.571828</td>\n",
       "      <td>0.571828</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.533214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>19.736156</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.576805</td>\n",
       "      <td>0.576805</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "      <td>0.548644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>21.391631</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.571087</td>\n",
       "      <td>0.571087</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "      <td>0.561005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>23.157683</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.570897</td>\n",
       "      <td>0.570897</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.598086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.464092</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.635536</td>\n",
       "      <td>0.635536</td>\n",
       "      <td>0.526568</td>\n",
       "      <td>0.526089</td>\n",
       "      <td>0.526568</td>\n",
       "      <td>0.526089</td>\n",
       "      <td>0.526568</td>\n",
       "      <td>0.526089</td>\n",
       "      <td>0.526568</td>\n",
       "      <td>0.526089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.460686</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.640064</td>\n",
       "      <td>0.639266</td>\n",
       "      <td>0.518851</td>\n",
       "      <td>0.518253</td>\n",
       "      <td>0.518851</td>\n",
       "      <td>0.518253</td>\n",
       "      <td>0.518851</td>\n",
       "      <td>0.518253</td>\n",
       "      <td>0.518851</td>\n",
       "      <td>0.518253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.352207</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.647622</td>\n",
       "      <td>0.647622</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.527911</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.527911</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.527911</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.527911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>39.456741</td>\n",
       "      <td>0.023996</td>\n",
       "      <td>0.624663</td>\n",
       "      <td>0.624663</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>42.004622</td>\n",
       "      <td>0.031253</td>\n",
       "      <td>0.615589</td>\n",
       "      <td>0.615589</td>\n",
       "      <td>0.586124</td>\n",
       "      <td>0.588517</td>\n",
       "      <td>0.586124</td>\n",
       "      <td>0.588517</td>\n",
       "      <td>0.586124</td>\n",
       "      <td>0.588517</td>\n",
       "      <td>0.586124</td>\n",
       "      <td>0.588517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth  training_size  Training_Time_My  Training_Time_Sk  \\\n",
       "0      4           50.0         14.934498          0.008349   \n",
       "1      4           60.0         17.813262          0.009103   \n",
       "2      4           70.0         19.736156          0.010004   \n",
       "3      4           80.0         21.391631          0.008013   \n",
       "4      4           90.0         23.157683          0.012002   \n",
       "5      7           50.0         28.464092          0.012001   \n",
       "6      7           60.0         33.460686          0.016004   \n",
       "7      7           70.0         37.352207          0.016005   \n",
       "8      7           80.0         39.456741          0.023996   \n",
       "9      7           90.0         42.004622          0.031253   \n",
       "\n",
       "   Training_Accuracy_My  Training_Accuracy_Sk  Testing_Accuracy_My  \\\n",
       "0              0.568487              0.568487             0.546673   \n",
       "1              0.571828              0.571828             0.533214   \n",
       "2              0.576805              0.576805             0.548644   \n",
       "3              0.571087              0.571087             0.561005   \n",
       "4              0.570897              0.570897             0.598086   \n",
       "5              0.635536              0.635536             0.526568   \n",
       "6              0.640064              0.639266             0.518851   \n",
       "7              0.647622              0.647622             0.526316   \n",
       "8              0.624663              0.624663             0.555024   \n",
       "9              0.615589              0.615589             0.586124   \n",
       "\n",
       "   Testing_Accuracy_Sk  Testing_F1_My  Testing_F1_Sk  Testing_Precision_My  \\\n",
       "0             0.546194       0.546673       0.546194              0.546673   \n",
       "1             0.533214       0.533214       0.533214              0.533214   \n",
       "2             0.548644       0.548644       0.548644              0.548644   \n",
       "3             0.561005       0.561005       0.561005              0.561005   \n",
       "4             0.598086       0.598086       0.598086              0.598086   \n",
       "5             0.526089       0.526568       0.526089              0.526568   \n",
       "6             0.518253       0.518851       0.518253              0.518851   \n",
       "7             0.527911       0.526316       0.527911              0.526316   \n",
       "8             0.552632       0.555024       0.552632              0.555024   \n",
       "9             0.588517       0.586124       0.588517              0.586124   \n",
       "\n",
       "   Testing_Precision_Sk  Testing_Recall_My  Testing_Recall_Sk  \n",
       "0              0.546194           0.546673           0.546194  \n",
       "1              0.533214           0.533214           0.533214  \n",
       "2              0.548644           0.548644           0.548644  \n",
       "3              0.561005           0.561005           0.561005  \n",
       "4              0.598086           0.598086           0.598086  \n",
       "5              0.526089           0.526568           0.526089  \n",
       "6              0.518253           0.518851           0.518253  \n",
       "7              0.527911           0.526316           0.527911  \n",
       "8              0.552632           0.555024           0.552632  \n",
       "9              0.588517           0.586124           0.588517  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_train_size_entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b503a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_train_size_entropy_df.to_csv('varying_train_size_entropy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62108dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e57eb0",
   "metadata": {},
   "source": [
    "## Comparing Accuracy and Time of my algo and Sklearn with varying training size (criterian-gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6addd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data into different train and test using different split value\n",
    "# Considering split from 50% to 90% train split\n",
    "train_size = [.5, .6, .7, .8, .9]\n",
    "depth = [4, 7]\n",
    "\n",
    "var_train_training_acc, var_train_training_acc_sk = [], []\n",
    "var_train_time, var_train_time_sk = [], []\n",
    "var_train_acc, var_train_acc_sk = [], []\n",
    "var_train_f1_score, var_train_f1_score_sk = [], []\n",
    "var_train_precision, var_train_precision_sk = [], []\n",
    "var_train_recall, var_train_recall_sk = [], []\n",
    "var_tree_depth, var_train_size = [], []\n",
    "  \n",
    "for d in depth:\n",
    "    for i in train_size:\n",
    "        var_tree_depth.append(d)\n",
    "        var_train_size.append(i*100)\n",
    "        \n",
    "        # Dividing into train and test based on split size\n",
    "        df_train, df_test = train_test_split(df, i)\n",
    "\n",
    "        # Calculation and training of model and training time of My Algo\n",
    "        start = time.time()\n",
    "        main_tree = decisionTreeClassifier(df_train, max_depth=d, split_type='gini')\n",
    "        end = time.time()\n",
    "        var_train_time.append(end-start)\n",
    "        #---------------------------------------------------------------------------------------\n",
    "        #---------------------------------------------------------------------------------------      \n",
    "        # Calculation and training of model and training time of sklearn model\n",
    "        start = time.time()\n",
    "        # Model Training\n",
    "        sk_model = DecisionTreeClassifier(criterion='gini', max_depth=d)\n",
    "        # fit the model\n",
    "        sk_model.fit(df_train.iloc[:, :-1], df_train.iloc[:, -1])\n",
    "        end = time.time()\n",
    "        # Storing training time taken into depth_time list\n",
    "        var_train_time_sk.append(end-start)\n",
    "        \n",
    "        \n",
    "        # Making prediction on training data\n",
    "        y_pred_train = predict(df_train.iloc[:, :-1], main_tree)\n",
    "        y_pred_train_sk = sk_model.predict(df_train.iloc[:, :-1])\n",
    "\n",
    "        # Finding Training Accuracy\n",
    "        y_accuracy_train = accuracy_score(df_train.iloc[:, -1], y_pred_train)\n",
    "        var_train_training_acc.append(y_accuracy_train)\n",
    "        #-----------------------------------------------------\n",
    "        y_accuracy_train_sk = accuracy_score(df_train.iloc[:, -1], y_pred_train_sk)\n",
    "        var_train_training_acc_sk.append(y_accuracy_train_sk)\n",
    "        \n",
    "        \n",
    "        # Making prediction on testing data\n",
    "        y_pred = predict(df_test, main_tree)\n",
    "        y_pred_sk = sk_model.predict(df_test.iloc[:, :-1])\n",
    "\n",
    "        # Finding Accuracy\n",
    "        y_accuracy = accuracy_score(df_test.iloc[:, -1], y_pred)\n",
    "        var_train_acc.append(y_accuracy)\n",
    "        #-----------------------------------------------------\n",
    "        y_accuracy_sk = accuracy_score(df_test.iloc[:, -1], y_pred_sk)\n",
    "        var_train_acc_sk.append(y_accuracy_sk)\n",
    "\n",
    "        # Finding F1-Score\n",
    "        y_f1_score = f1_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_f1_score.append(y_f1_score)\n",
    "        #------------------------------------------------------\n",
    "        y_f1_score_sk = f1_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_f1_score_sk.append(y_f1_score_sk)\n",
    "\n",
    "        # Finding Precision\n",
    "        y_precision = precision_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_precision.append(y_precision)\n",
    "        #------------------------------------------------------\n",
    "        y_precision_sk = precision_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_precision_sk.append(y_precision_sk)\n",
    "\n",
    "        # Finding Recall\n",
    "        y_recall = recall_score(df_test.iloc[:, -1], y_pred, average='micro')\n",
    "        var_train_recall.append(y_recall)\n",
    "        #--------------------------------------------------------\n",
    "        y_recall_sk = recall_score(df_test.iloc[:, -1], y_pred_sk, average='micro')\n",
    "        var_train_recall_sk.append(y_recall_sk)\n",
    "        \n",
    "# Creating dataframe of all the results achieved\n",
    "varying_train_size_gini_dict = {'Depth': var_tree_depth,\n",
    "                                 'training_size':var_train_size, \n",
    "                                 'Training_Time_My':var_train_time,\n",
    "                                 'Training_Time_Sk':var_train_time_sk,\n",
    "                                 'Training_Accuracy_My':var_train_training_acc,\n",
    "                                 'Training_Accuracy_Sk':var_train_training_acc_sk,\n",
    "                                 'Testing_Accuracy_My':var_train_acc,\n",
    "                                 'Testing_Accuracy_Sk':var_train_acc_sk,\n",
    "                                 'Testing_F1_My':var_train_f1_score, \n",
    "                                 'Testing_F1_Sk':var_train_f1_score_sk,\n",
    "                                 'Testing_Precision_My':var_train_precision, \n",
    "                                 'Testing_Precision_Sk':var_train_precision_sk,\n",
    "                                 'Testing_Recall_My':var_train_recall, \n",
    "                                 'Testing_Recall_Sk':var_train_recall_sk }\n",
    "\n",
    "\n",
    "varying_train_size_gini_df = pd.DataFrame(varying_train_size_gini_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ea89359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>training_size</th>\n",
       "      <th>Training_Time_My</th>\n",
       "      <th>Training_Time_Sk</th>\n",
       "      <th>Training_Accuracy_My</th>\n",
       "      <th>Training_Accuracy_Sk</th>\n",
       "      <th>Testing_Accuracy_My</th>\n",
       "      <th>Testing_Accuracy_Sk</th>\n",
       "      <th>Testing_F1_My</th>\n",
       "      <th>Testing_F1_Sk</th>\n",
       "      <th>Testing_Precision_My</th>\n",
       "      <th>Testing_Precision_Sk</th>\n",
       "      <th>Testing_Recall_My</th>\n",
       "      <th>Testing_Recall_Sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>17.806508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571839</td>\n",
       "      <td>0.558429</td>\n",
       "      <td>0.544758</td>\n",
       "      <td>0.536142</td>\n",
       "      <td>0.544758</td>\n",
       "      <td>0.536142</td>\n",
       "      <td>0.544758</td>\n",
       "      <td>0.536142</td>\n",
       "      <td>0.544758</td>\n",
       "      <td>0.536142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.873926</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.569034</td>\n",
       "      <td>0.567837</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>0.533214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>19.893050</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.573384</td>\n",
       "      <td>0.580226</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.549442</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>21.291197</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.567195</td>\n",
       "      <td>0.569291</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "      <td>0.556220</td>\n",
       "      <td>0.558612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>23.052211</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>0.572227</td>\n",
       "      <td>0.569034</td>\n",
       "      <td>0.610048</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.610048</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.610048</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.610048</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.280252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644157</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>0.531833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.994517</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>0.653232</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.533812</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.533812</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.533812</td>\n",
       "      <td>0.534411</td>\n",
       "      <td>0.533812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.923127</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.656859</td>\n",
       "      <td>0.656175</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.967876</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.628554</td>\n",
       "      <td>0.621371</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>0.551435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>43.771972</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.618250</td>\n",
       "      <td>0.621442</td>\n",
       "      <td>0.602871</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.602871</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.602871</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.602871</td>\n",
       "      <td>0.576555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth  training_size  Training_Time_My  Training_Time_Sk  \\\n",
       "0      4           50.0         17.806508          0.000000   \n",
       "1      4           60.0         17.873926          0.007002   \n",
       "2      4           70.0         19.893050          0.012002   \n",
       "3      4           80.0         21.291197          0.008002   \n",
       "4      4           90.0         23.052211          0.012055   \n",
       "5      7           50.0         29.280252          0.000000   \n",
       "6      7           60.0         33.994517          0.012004   \n",
       "7      7           70.0         38.923127          0.011994   \n",
       "8      7           80.0         40.967876          0.012002   \n",
       "9      7           90.0         43.771972          0.016004   \n",
       "\n",
       "   Training_Accuracy_My  Training_Accuracy_Sk  Testing_Accuracy_My  \\\n",
       "0              0.571839              0.558429             0.544758   \n",
       "1              0.569034              0.567837             0.540395   \n",
       "2              0.573384              0.580226             0.549442   \n",
       "3              0.567195              0.569291             0.556220   \n",
       "4              0.572227              0.569034             0.610048   \n",
       "5              0.644157              0.650862             0.519866   \n",
       "6              0.635674              0.653232             0.534411   \n",
       "7              0.656859              0.656175             0.523126   \n",
       "8              0.628554              0.621371             0.574163   \n",
       "9              0.618250              0.621442             0.602871   \n",
       "\n",
       "   Testing_Accuracy_Sk  Testing_F1_My  Testing_F1_Sk  Testing_Precision_My  \\\n",
       "0             0.536142       0.544758       0.536142              0.544758   \n",
       "1             0.533214       0.540395       0.533214              0.540395   \n",
       "2             0.552632       0.549442       0.552632              0.549442   \n",
       "3             0.558612       0.556220       0.558612              0.556220   \n",
       "4             0.578947       0.610048       0.578947              0.610048   \n",
       "5             0.531833       0.519866       0.531833              0.519866   \n",
       "6             0.533812       0.534411       0.533812              0.534411   \n",
       "7             0.531100       0.523126       0.531100              0.523126   \n",
       "8             0.551435       0.574163       0.551435              0.574163   \n",
       "9             0.576555       0.602871       0.576555              0.602871   \n",
       "\n",
       "   Testing_Precision_Sk  Testing_Recall_My  Testing_Recall_Sk  \n",
       "0              0.536142           0.544758           0.536142  \n",
       "1              0.533214           0.540395           0.533214  \n",
       "2              0.552632           0.549442           0.552632  \n",
       "3              0.558612           0.556220           0.558612  \n",
       "4              0.578947           0.610048           0.578947  \n",
       "5              0.531833           0.519866           0.531833  \n",
       "6              0.533812           0.534411           0.533812  \n",
       "7              0.531100           0.523126           0.531100  \n",
       "8              0.551435           0.574163           0.551435  \n",
       "9              0.576555           0.602871           0.576555  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_train_size_gini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46471962",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_train_size_gini_df.to_csv('varying_train_size_gini_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c834d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f590c0",
   "metadata": {},
   "source": [
    "# Plotting of charts for reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad764a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv('varying_train_size_entropy_df.csv')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "# For training accuracy (Information gain)\n",
    "sns.lineplot(ax=axes[0,0], x = 'training_size', y='Training_Accuracy_My', data=da, hue='Depth')\n",
    "sns.lineplot(ax=axes[0,1], x='training_size', y='Training_Accuracy_Sk', data=da, hue='Depth')\n",
    "axes[0,0].set_title(\"Training Accuracy of My model (IG)\")\n",
    "axes[0,1].set_title(\"Training Accuracy of Sklearn model (IG)\")\n",
    "\n",
    "# For testing accuracy (Information Gain)\n",
    "sns.lineplot(ax=axes[1,0], x = 'training_size', y='Testing_Accuracy_My', data=da, hue='Depth')\n",
    "sns.lineplot(ax=axes[1,1], x='training_size', y='Testing_Accuracy_Sk', data=da, hue='Depth')\n",
    "axes[1,0].set_title(\"Testing Accuracy of My model (IG)\")\n",
    "axes[1,1].set_title(\"Testing Accuracy of Sklearn model (IG)\")\n",
    "\n",
    "\n",
    "\n",
    "axes[0,0].grid()\n",
    "axes[0,1].grid()\n",
    "axes[1,0].grid()\n",
    "axes[1,1].grid()\n",
    "fig.tight_layout(pad=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dce347",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('varying_train_size_gini_df.csv')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "# For training accuracy(Gini)\n",
    "sns.lineplot(ax=axes[0,0], x = 'training_size', y='Training_Accuracy_My', data=db, hue='Depth')\n",
    "sns.lineplot(ax=axes[0,1], x='training_size', y='Training_Accuracy_Sk', data=db, hue='Depth')\n",
    "axes[0,0].set_title(\"Training Accuracy of My model (Gini)\")\n",
    "axes[0,1].set_title(\"Training Accuracy of Sklearn model (Gini)\")\n",
    "\n",
    "# For testing accuracy(Gini)\n",
    "sns.lineplot(ax=axes[1,0], x = 'training_size', y='Testing_Accuracy_My', data=db, hue='Depth')\n",
    "sns.lineplot(ax=axes[1,1], x='training_size', y='Testing_Accuracy_Sk', data=db, hue='Depth')\n",
    "axes[1,0].set_title(\"Testing Accuracy of My model (Gini)\")\n",
    "axes[1,1].set_title(\"Testing Accuracy of Sklearn model (Gini)\")\n",
    "\n",
    "axes[0,0].grid()\n",
    "axes[0,1].grid()\n",
    "axes[1,0].grid()\n",
    "axes[1,1].grid()\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "#fig.set_title(\"Variation in training and testing accuracy based on training size\", fontsize=16, y=-0.3, x=0.02, loc=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b3654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e1ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2aeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a4b4405",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
